# -*- coding: utf-8 -*-
"""
Created on Tue Sep 21 15:43:48 2021
@author: Seyed Omid Sajedi 
Update on Thu Sep 23 - Data Augmentation Implementation - K. A. Eltouny"""


# import cv2
# import albumentations as A
import torch

import PIL
from PIL import Image
from OsUtils import load_pickle
import numpy as np
import random
import pandas as pd

    
def pkl_to_df_split(split_name):
    split_dict_set=load_pickle('split_dictionaries/'+split_name+'_dict')
    return pd.DataFrame.from_dict(split_dict_set,orient='index')

def get_noisy_crop_corners(config,n_crop_h,n_crop_w,crop_noise_amp):
    crop_c_arr=np.zeros((n_crop_h,n_crop_w,2))

    for i_row in range(n_crop_h):
        for j_col in range(n_crop_w):
            crop_c_arr[i_row,j_col,0]=int(config.img_size*(i_row+0.5))
            crop_c_arr[i_row,j_col,1]=int(config.img_size*(j_col+0.5))
            
    rand_noise_arr=np.random.rand(n_crop_h,n_crop_w,2)
    rand_noise_arr=(rand_noise_arr-0.5)*crop_noise_amp
    rand_noise_arr[rand_noise_arr[:,0,1]<0.0,0,1]=0  
    rand_noise_arr[rand_noise_arr[:,-1,1]>0.0,-1,1]=0  
    rand_noise_arr[0,rand_noise_arr[0,:,0]<0.0,0]=0  
    rand_noise_arr[-1,rand_noise_arr[-1,:,0]>0.0,0]=0 
    
    # move to center if out
    
    crop_c_arr_rand=crop_c_arr+0.5*config.img_size*rand_noise_arr
    crop_corner_rand=crop_c_arr_rand-0.5*config.img_size
    

    crop_corner_rand=crop_corner_rand.astype(int)
    crop_c_arr_rand=crop_c_arr_rand.astype(int)
    high_corner_bin_rand=crop_corner_rand+config.img_size  
    
    
    return high_corner_bin_rand

def noisy_crop_reshape(tensor,config,n_crop_h,n_crop_w,crop_noise_amp,high_corner_bin_rand=None):
    if high_corner_bin_rand is None:
        high_corner_bin_rand=get_noisy_crop_corners(config,n_crop_h,n_crop_w,crop_noise_amp)
    
    new_tensor_shape=(n_crop_h,n_crop_w,config.img_size,config.img_size,tensor.shape[-1])

    reshaped_tensor=np.zeros(new_tensor_shape)
    # print(tensor.shape)
    for i_row in range(n_crop_h):
        for j_col in range(n_crop_w):
            hc_row=high_corner_bin_rand[i_row,j_col,0]
            hc_col=high_corner_bin_rand[i_row,j_col,1]
            reshaped_tensor[i_row,j_col]=tensor[hc_row-config.img_size:hc_row,hc_col-config.img_size:hc_col]
    return reshaped_tensor,high_corner_bin_rand

class torch_ViT_DataGenerator:

    'Generate input, output data for the damage patch classification'
    
    """
        This class is used to create a keras data generator.
        Parameters:
        -----------
            loader_object : <obj>
                A loader object built by the CompDataLoader
            
            batch_size_img : <int>
                The training batchsize will be this value x number of crops.
                The default is 5
                
            augmenter : <albumentations augmenter>, optional, default=None
                An augmenter generated by albumentations library
                Must be defined if augmentation_times > 1
                
            P_aug : probability of performing any augmentation, The default is 0.5
                                                
            augmentation_times: <int>, optional, default=0
                                The number of times each sample in the original dataset is augmented and appended
                                to the used dataset.
                                e.g.: for augmentation_times = 2 and an original dataset of 3000 samples, the size of the dataset
                                becomes 9000 samples with 6000 samples augmented from the original 3000 original samples.
                                
            label_id : int
                label considred for binary classification. The default is 1 (crack)
                 
    """
    def __init__(self, 
                 config,
                 split_name,
                 main_dir='../../Dataset',
                 batch_size_img=5,
                 shuffle=False,
                 bg_augmenter=None,
                 augmenter=None,    
                 rand_lr_flip=False,
                 rand_ud_flip=False,
                 P_aug=0.5,
                 label_type_list=['crack','rebar','spall'],
                 n_crop_h=9,
                 n_crop_w=16,
                 resize_img=False,
                 new_size=(1920,1080),
                 noisy_crop=True,
                 crop_noise_amp=1,
                 use_cache_img=False,
                 use_cache_mask=True,
                 return_mask=True,
                 return_seg=False,
                 filter_bg=True,
                 P_rand_keep_bg=0.0,
                 zero_pad=None, # (40,96)
                 random_pad=False
                 ):   
        
        'Initialization'
        self.config=config
        self.main_dir=main_dir
        self.bg_augmenter = bg_augmenter
        self.augmenter = augmenter      
        self.rand_lr_flip=rand_lr_flip
        self.rand_ud_flip=rand_ud_flip
        self.P_aug=P_aug
        self.shuffle=shuffle
        self.split_name=split_name
        self.batch_size_img=batch_size_img
        self.label_type_list=label_type_list
        self.use_cache_img=use_cache_img
        self.use_cache_mask=use_cache_mask
        self.n_crop_h=n_crop_h
        self.n_crop_w=n_crop_w
        self.resize_img=resize_img
        self.new_size=new_size
        self.noisy_crop=noisy_crop
        self.crop_noise_amp=crop_noise_amp
        self.return_mask=return_mask
        self.return_seg=return_seg
        self.filter_bg=filter_bg
        self.zero_pad=zero_pad
        self.random_pad=random_pad
        self.P_rand_keep_bg=P_rand_keep_bg

        # Additional dataset properties
        
        # self.label_str=self.label_type_list[self.label_id]
        self.main_img_h=new_size[1]
        self.main_img_w=new_size[0]
        self.split_df=pkl_to_df_split(split_name)      
        if self.zero_pad is not None:
            self.crop_h=int((self.main_img_h+self.zero_pad[0])/self.n_crop_h)
            self.crop_w=int((self.main_img_w+self.zero_pad[1])/self.n_crop_w)          
        else:
            self.crop_h=int(self.main_img_h/self.n_crop_h)
            self.crop_w=int(self.main_img_w/self.n_crop_w)     
        self.n_classes=len(self.label_type_list)
        self.n_img_total=len(self.split_df)
        self.n_crop=n_crop_h*n_crop_w
        self.n_obs_total=self.n_crop*self.n_img_total
        self.batch_size=self.batch_size_img*self.n_crop
        self.n_batch_img=int(np.ceil(self.n_img_total / self.batch_size_img))  #int(np.ceil(self.n_img_total / self.batch_size_img)) #100 
        self.indx_bin=np.arange(0,self.n_img_total,1) # np.arange(0,self.n_img_total,1) #np.arange(0,50,1) #
        
        if self.shuffle:
            random.shuffle(self.indx_bin)
        
        self.batch_indx_bin=np.array_split(self.indx_bin, self.n_batch_img)
        self.batch_counter=0
        
        # caching
        # Inspired by https://github.com/johschmidt42/PyTorch-2D-3D-UNet-Tutorial/blob/master/customdatasets.py
        if self.use_cache_mask:
            self.cached_mask=[]
            for i_m in np.arange(0,self.n_img_total,1):
                self.cached_mask.append(self.load_mask(i_m))
            self.cached_mask=np.array(self.cached_mask)       
                
        if self.use_cache_img:
            self.cached_img=[]
            for i_m in np.arange(0,self.n_img_total,1):
                self.cached_img.append(self.load_img(i_m))
            self.cached_img=np.array(self.cached_img) 
        
        print('images in the %s= %d, n_batch_img=%d, batch_size=%d, n_total=%d'%(self.split_name,self.n_img_total,self.n_batch_img,
                                                                                 self.batch_size, self.n_obs_total))
    def get_fname(self,img_id):
        return self.split_df.iloc[img_id]['fname']
        
    def load_img(self,img_id,pad_h=0,pad_v=0):
        path=self.split_df.iloc[img_id]['fname']
        img=Image.open(self.main_dir+'/image/'+path)

        if self.resize_img:
            img=img.resize(self.new_size,resample=PIL.Image.LANCZOS)
        
        img=np.array(img)
        if self.zero_pad is not None:
            if pad_h==0:
                h_pad_tup=(self.zero_pad[0],0)
            if pad_h==1:
                h_pad_tup=(0,self.zero_pad[0]) 
            if pad_h==2:
                h_pad_tup=(self.zero_pad[0]-self.zero_pad[0]//2,self.zero_pad[0]//2) 
            if pad_v==0:
                v_pad_tup=(self.zero_pad[1],0)
            if pad_v==1:
                v_pad_tup=(0,self.zero_pad[1])   
            if pad_v==2:
                v_pad_tup=(self.zero_pad[1]-self.zero_pad[1]//2,self.zero_pad[1]//2)   
                
            img=np.pad(img,(h_pad_tup,v_pad_tup,(0,0)))
        return img

    def load_mask(self,img_id,pad_h=0,pad_v=0):
        path=self.split_df.iloc[img_id]['fname']

        mask_bin=[]
        for i_type in self.label_type_list:
            mask_bin.append(Image.open(self.main_dir+'/label/'+i_type+'/'+path))
                            
        if self.resize_img:
            for i_m,i_mask in enumerate(mask_bin):
                mask_bin[i_m]=mask_bin[i_m].resize(self.new_size,resample=PIL.Image.LANCZOS)
                    
        mask_comb=np.zeros((self.new_size[1],self.new_size[0],self.n_classes,))
        for i_m,i_mask in enumerate(mask_bin): 
            mask_comb[:,:,i_m]=np.array(i_mask)
            # mask_comb[mask_comb==100]=self.n_classes-1    
        mask_comb= np.array(mask_comb,dtype=np.int8)     
        if self.zero_pad is not None:
            if pad_h==0:
                h_pad_tup=(self.zero_pad[0],0)
            if pad_h==1:
                h_pad_tup=(0,self.zero_pad[0]) 
            if pad_h==2:
                h_pad_tup=(self.zero_pad[0]-self.zero_pad[0]//2,self.zero_pad[0]//2) 
            if pad_v==0:
                v_pad_tup=(self.zero_pad[1],0)
            if pad_v==1:
                v_pad_tup=(0,self.zero_pad[1])   
            if pad_v==2:
                v_pad_tup=(self.zero_pad[1]-self.zero_pad[1]//2,self.zero_pad[1]//2)    
                
            mask_comb=np.pad(mask_comb,(h_pad_tup,v_pad_tup,(0,0)))        
        return mask_comb
        
    def get_data(self,img_id,pad_h=0,pad_v=0):
        data=[]
        if self.use_cache_img:
            data.append(self.cached_img[img_id])
        else:
            data.append(self.load_img(img_id,pad_h=pad_h,pad_v=pad_v))
        if self.return_mask:
            if self.use_cache_mask:
                data.append(self.cached_mask[img_id])
            else:
                data.append(self.load_mask(img_id,pad_h=pad_h,pad_v=pad_v))       
        return data                
    
    def augment_data(self,data):
        if self.return_mask and np.random.rand()<self.P_aug:
            if self.augmenter is not None:
                # mask_cat = np.expand_dims(data[1],-1)
                mask_reordered = np.moveaxis(data[1], -1, 0)
                mask_list = list(mask_reordered)
                augmented = self.augmenter(image=data[0], masks=mask_list)
                data[0] = augmented['image']
                data[1] = np.stack(augmented['masks'], axis=2)
                
        if self.return_mask:     
            if self.rand_lr_flip and np.random.rand()<self.P_aug:
                data[0]=np.flip(data[0],1)
                data[1]=np.flip(data[1],1)
            if self.rand_ud_flip and np.random.rand()<self.P_aug:
                data[0]=np.flip(data[0],0)
                data[1]=np.flip(data[1],0)
                
        return data
        
    def __getitem__(self, b_index,return_seg_mask=False,pad_h=0,pad_v=0):  
        
        # Generate data
        # Store sample
        index_bin_img_i=self.batch_indx_bin[b_index]
        n_img_batch=index_bin_img_i.shape[0]
        img_bin = np.empty((n_img_batch, self.n_crop_h,self.n_crop_w,self.crop_h,self.crop_w, 3))
        if self.random_pad:
            pad_h=np.random.randint(3)
            pad_v=np.random.randint(3)
            
        if self.return_mask:
            mask_bin = np.empty((n_img_batch, self.n_crop_h,self.n_crop_w,self.crop_h,self.crop_w,self.n_classes), dtype=np.int8)
        
        for i,ID_img in enumerate(index_bin_img_i):
            
            data=self.get_data(ID_img,pad_h=pad_h,pad_v=pad_v)
            data=self.augment_data(data)
            # reshape the original images and masks into small crops
            
            if self.noisy_crop: # take random crops
                img_bin[i],high_corner_bin_rand=noisy_crop_reshape(data[0],self.config,self.n_crop_h,self.n_crop_w,self.crop_noise_amp,high_corner_bin_rand=None)
                if self.return_mask:
                    mask_bin[i],_=noisy_crop_reshape(data[1],self.config,self.n_crop_h,self.n_crop_w,self.crop_noise_amp,high_corner_bin_rand=high_corner_bin_rand)
            else: # simply reshape the loaded array
            
                img_bin[i]=np.reshape(data[0],
                                      (self.n_crop_h,self.crop_h,
                                       self.n_crop_w,self.crop_w,3)
                                       ).swapaxes(1, 2)
                
                if self.return_mask:
                    mask_bin[i]=np.reshape(data[1],
                                      (self.n_crop_h,self.crop_h,
                                       self.n_crop_w,self.crop_w,self.n_classes)
                                       ).swapaxes(1, 2)
        
        # merge the img and crop dimensions
        img_bin=img_bin.reshape((-1,)+img_bin.shape[3:])
        if self.return_mask:
            mask_bin=mask_bin.reshape((-1,)+mask_bin.shape[3:])
        batch_size=img_bin.shape[0]
        # Now reshape crops into even smaller patches
        norm_RGB=255
        X = img_bin/norm_RGB
        X = X.swapaxes(1,3).swapaxes(2,3)
    
        data=[]
        if self.return_mask:
            Y_mask=mask_bin.reshape((batch_size,-1,self.n_classes))
            Y_tag_crit=np.amax(np.amax(Y_mask,axis=1),axis=1)
            dmg_crop_indx_bin=np.where(Y_tag_crit!=0)
        
        P_rand_bg=np.random.rand()
        if self.filter_bg and self.return_mask and P_rand_bg>self.P_rand_keep_bg:
            X=X[dmg_crop_indx_bin[0]]
            
        data.append(torch.from_numpy(X).float())   
        if self.return_mask:
            if self.return_seg:
                if self.filter_bg and P_rand_bg>self.P_rand_keep_bg:
                    Y=mask_bin[dmg_crop_indx_bin[0]]
                else:
                    Y=mask_bin
            else:
                Y=np.amax(Y_mask,axis=1)
            data.append(torch.from_numpy(Y).float())
            if return_seg_mask:
                data.append(torch.from_numpy(Y_mask).float())

        self.batch_counter+=1
        if self.batch_counter==self.n_batch_img and self.shuffle: # reset and shuffle after last batch is fed
            self.batch_counter=0
            random.shuffle(self.indx_bin)
            self.batch_indx_bin=np.array_split(self.indx_bin, self.n_batch_img)
        
        return data 
    
    def __len__(self):
        return self.n_batch_img
